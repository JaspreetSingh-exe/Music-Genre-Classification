# **ğŸµ Music Genre Classification ğŸ¶**
A deep learning-based system to classify music genres using **SVM, CNN, LSTM, and Transformer models**, with **YAMNet-based feature extraction**.  

## **ğŸš€ Features**
âœ… **Extracts audio features** using **YAMNet embeddings**.  
âœ… **Trains multiple models** (**SVM, CNN, LSTM, Transformer**) for comparative analysis.  
âœ… **Evaluates model performance** using accuracy, confusion matrices, and classification reports.  
âœ… **Allows users to upload an audio file** for real-time genre classification.  

---

## **ğŸµ What is YAMNet?**
YAMNet is a **pre-trained deep learning model developed by Google** for **audio classification**. It is based on **MobileNet architecture** and is trained on **AudioSet**, a large-scale dataset of sounds. YAMNet extracts **high-level embeddings** from audio, which can be used for various machine learning tasks, including **music genre classification**.

### **ğŸ¯ Why YAMNet?**
- ğŸŸ¢ **Pre-trained on large-scale data** (AudioSet)
- ğŸŸ¢ **Extracts meaningful sound features**
- ğŸŸ¢ **Lightweight and efficient for real-time applications**

### **ğŸ“Œ Using YAMNet for Feature Extraction**
To extract features from an audio file using YAMNet in Python:

```python
import tensorflow_hub as hub
import numpy as np
import librosa

# Load the YAMNet model
yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')

# Load and preprocess the audio file
def extract_yamnet_features(audio_path):
    waveform, sr = librosa.load(audio_path, sr=16000)  # Ensure 16kHz sample rate
    waveform = np.reshape(waveform, (1, -1))  # Reshape to match model input
    
    # Run YAMNet model
    embeddings, scores, spectrogram = yamnet_model(waveform)
    return embeddings.numpy()

# Example usage
features = extract_yamnet_features('test_music(hiphop).wav')
print(features.shape)  # Output shape: (number of frames, 1024)
```

ğŸ”— **Reference:** [TensorFlow YAMNet Tutorial](https://www.tensorflow.org/hub/tutorials/yamnet)

---

## **ğŸ“‚ Project Structure**
```
ğŸŒ† Music Genre Classification
 â”œâ”€â”€ ğŸ“‚ Data
 â”‚   â”œâ”€â”€ ğŸ“‚ genres_original        # Raw music dataset organized by genre
 â”‚   â”œâ”€â”€ ğŸ“‚ images_original        # Spectrogram images (if applicable)
 â”‚   â”œâ”€â”€ ğŸ“ music_features.csv     # Extracted features dataset
 â”‚   â”œâ”€â”€ ğŸ“ test_music(hiphop).wav # Sample test audio file
 â”‚   â”œâ”€â”€ ğŸ“ yamnet_features.csv    # YAMNet feature embeddings
 â”‚
 â”œâ”€â”€ ğŸ“‚ Models
 â”‚   â”œâ”€â”€ ğŸ“ cnn_model.h5           # Trained CNN model
 â”‚   â”œâ”€â”€ ğŸ“ lstm_model.h5          # Trained LSTM model
 â”‚   â”œâ”€â”€ ğŸ“ svm_model.pkl          # Trained SVM model
 â”‚   â”œâ”€â”€ ğŸ“ transformer_model.h5   # Trained Transformer model
 â”‚
 â”œâ”€â”€ ğŸ“ .gitattributes             # Git LFS tracking for large files
 â”œâ”€â”€ ğŸ“ requirements.txt           # Required dependencies
 â”œâ”€â”€ ğŸ“ FeatureExtraction.ipynb    # Extracts YAMNet features from audio
 â”œâ”€â”€ ğŸ“ MusicGenreModels.ipynb     # Trains all ML models (SVM, CNN, LSTM, Transformer)
 â”œâ”€â”€ ğŸ“ Result_Analysis.ipynb      # Evaluates model performance & visualization
```

---

## **ğŸ› ï¸ Setup & Installation**
### **1âƒ£ Clone the Repository**
```sh
git clone https://github.com/JaspreetSingh-exe/Music-Genre-Classification.git
cd Music-Genre-Classification
```

### **2âƒ£ Install Dependencies**
```sh
pip install -r requirements.txt
```

### **3âƒ£ Download & Install Git LFS (For Large Model Files)**
```sh
git lfs install
git lfs pull
```

---

## **ğŸµ How to Run the Project**
### **1âƒ£ Extract Features from Audio**
Run:
```sh
jupyter notebook FeatureExtraction.ipynb
```
This extracts **YAMNet embeddings** from the dataset.

### **2âƒ£ Train Models**
Run:
```sh
jupyter notebook MusicGenreModels.ipynb
```
This trains **SVM, CNN, LSTM, Transformer** models and saves them in the `Models/` directory.

### **3âƒ£ Evaluate Model Performance**
Run:
```sh
jupyter notebook Result_Analysis.ipynb
```
This generates **accuracy scores, confusion matrices, and classification reports**.

### **4âƒ£ Predict Genre for a New Audio File**
Run in Python:
```python
from MusicGenreModels import predict_audio_file
predict_audio_file("path/to/audio.wav", models, scaler, label_encoder)
```

---

## **ğŸ“Š Model Comparison**
| Model         | Accuracy |
|--------------|----------|
| **SVM**        | 86.11% (best) |
| **CNN**        | 80.56% (overfitting) |
| **LSTM**       | 71.67% |
| **Transformer** | 33.33% |


---

## **ğŸ“Œ Future Improvements**
- âœ… Deploy as a **Web App** where users can upload songs & get genre predictions.
- âœ… Improve accuracy using **larger datasets** & **better preprocessing**.
- âœ… Experiment with **other pre-trained models** for better feature extraction.

---

## **ğŸœ License**
This project is licensed under the **MIT License**.

---

## **ğŸ“ Contact**
ğŸ’¡ **Author:** Jaspreet Singh  
ğŸ“ **Email:** jaspreetsingh01110@gmail.com   
ğŸ”— **GitHub:** [JaspreetSingh-exe](https://github.com/JaspreetSingh-exe)  

---

